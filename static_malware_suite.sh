#!/usr/bin/env bash
set -euo pipefail

# Static Malware Analysis Suite for Kali Linux
# Modes:
#   install                          -> installs tools via apt/pip
#   analyze <sample> [outdir] [rules_dir] [retdec:on|off]
#                                     outdir default: /home/kali/Desktop
#                                     rules_dir: folder with YARA rules (optional)
#                                     retdec: turn RetDec decompile on/off (default: off)

THIS="$(basename "$0")"

usage() {
  cat <<USAGE
Usage:
  $THIS install
  $THIS analyze <sample_path> [output_base_dir] [yara_rules_dir] [retdec:on|off]

Examples:
  $THIS install
  $THIS analyze ./mal.exe
  $THIS analyze ./mal.exe /home/kali/Desktop
  $THIS analyze ./mal.exe /home/kali/Desktop /home/kali/yara-rules retdec:on
USAGE
  exit 1
}

msg() { echo -e "[*] $*"; }
ok()  { echo -e "[+] $*"; }
warn(){ echo -e "[-] $*" >&2; }

install_tools() {
  msg "Updating apt and installing core tools..."
  sudo apt update
  sudo apt install -y \
    radare2 cutter ghidra retdec \
    yara exiftool binwalk ssdeep sdhash jq \
    python3 python3-pip python3-venv \
    upx-ucl binutils file \
    objdump || true

  # Detect It Easy (CLI: diec) – package name can vary; try both
  sudo apt install -y detect-it-easy || true
  sudo apt install -y die || true

  msg "Installing Python tooling (pefile, lief, floss, capa)..."
  python3 -m pip install --upgrade pip
  # pefile + lief for PE header parsing, entropy, imphash
  pip3 install --upgrade pefile lief
  # FLOSS (stackstrings, obfuscated strings)
  pip3 install --upgrade floss || pip3 install --upgrade flare-floss || true
  # CAPA (ATT&CK mapping)
  pip3 install --upgrade flare-capa || pip3 install --upgrade capa

  ok "Install complete. If 'diec' is missing, grab the AppImage from Detect-It-Easy later."
}

analyze_sample() {
  local SAMPLE="${1:-}"; [[ -z "${SAMPLE}" ]] && usage
  local OUTBASE="${2:-/home/kali/Desktop}"
  local YARA_RULES="${3:-}"
  local RETDEC_SWITCH="${4:-off}"

  [[ -r "$SAMPLE" ]] || { warn "Cannot read sample: $SAMPLE"; exit 3; }
  mkdir -p "$OUTBASE"

  # Tools sanity (do not hard-fail on optional tools)
  for t in rabin2 r2 objdump sha256sum strings exiftool binwalk ssdeep jq; do
    command -v "$t" >/dev/null 2>&1 || warn "Missing tool: $t (some outputs skipped)"
  done
  command -v capa >/dev/null 2>&1 || warn "capa not found (MITRE mapping skipped)"
  command -v floss >/dev/null 2>&1 || command -v floss.exe >/dev/null 2>&1 || warn "floss not found"
  command -v diec >/dev/null 2>&1 || warn "diec not found"
  command -v sdhash >/dev/null 2>&1 || warn "sdhash not found"
  command -v upx >/dev/null 2>&1 || warn "upx not found"
  command -v retdec-decompiler.py >/dev/null 2>&1 || [[ "$RETDEC_SWITCH" != "on" ]] || warn "retdec not found; decompile skipped"

  local SNAME="$(basename "$SAMPLE")"
  local STAMP="$(date +%Y%m%d_%H%M%S)"
  local OUTDIR="${OUTBASE%/}/${SNAME}_static_${STAMP}"
  mkdir -p "$OUTDIR"
  ok "Output directory: $OUTDIR"

  cp -f -- "$SAMPLE" "$OUTDIR/"

  # 00) HASHES
  msg "Hashing..."
  (sha256sum "$SAMPLE" || true) | tee "$OUTDIR/hash_sha256.txt"
  (sha1sum   "$SAMPLE" || true) | tee "$OUTDIR/hash_sha1.txt"
  (md5sum    "$SAMPLE" || true) | tee "$OUTDIR/hash_md5.txt"
  (ssdeep    "$SAMPLE" || true) > "$OUTDIR/hash_ssdeep.txt" || true
  (sdhash    "$SAMPLE" || true) > "$OUTDIR/hash_sdhash.txt" || true

  # 01) Basic info
  (file "$SAMPLE" || true)            | tee "$OUTDIR/01_file.txt"
  (rabin2 -I "$SAMPLE" || true)       > "$OUTDIR/02_info_rabin2.txt"
  (objdump -h "$SAMPLE" || true)      > "$OUTDIR/03_sections_objdump.txt"
  (rabin2 -S "$SAMPLE" || true)       > "$OUTDIR/04_sections_rabin2.txt"
  (rabin2 -L "$SAMPLE" || true)       > "$OUTDIR/05_libraries.txt"
  (rabin2 -i "$SAMPLE" || true)       > "$OUTDIR/06_imports.txt"
  (rabin2 -E "$SAMPLE" || true)       > "$OUTDIR/07_exports.txt"
  (rabin2 -R "$SAMPLE" || true)       > "$OUTDIR/08_relocations.txt"
  (rabin2 -U "$SAMPLE" || true)       > "$OUTDIR/09_resources.txt"

  # 02) Strings: classic + offset-rich + deobfuscated (floss)
  msg "Strings..."
  (strings -a -td "$SAMPLE" || true)  > "$OUTDIR/10_strings_strings.txt"
  (rabin2 -zz "$SAMPLE" || true)      > "$OUTDIR/11_strings_rabin2_offsets.txt"
  if command -v floss >/dev/null 2>&1; then
    (floss -q "$SAMPLE" || true)      > "$OUTDIR/12_strings_floss.txt"
  elif command -v floss.exe >/dev/null 2>&1; then
    (floss.exe -q "$SAMPLE" || true)  > "$OUTDIR/12_strings_floss.txt"
  fi

  # 03) PE metadata via Python (imphash, compile time, section entropy JSON/CSV)
  msg "PE metadata & entropy..."
  python3 - "$SAMPLE" "$OUTDIR" <<'PY'
import sys, json, math, pefile, os, datetime
fn, outdir = sys.argv[1], sys.argv[2]
pe = pefile.PE(fn, fast_load=False)
pe.parse_data_directories()
def entropy(b):
    if not b: return 0.0
    from collections import Counter
    c=Counter(b)
    ln=len(b)
    import math
    return -sum((v/ln)*math.log2(v/ln) for v in c.values())
info = {}
info['compile_timestamp'] = datetime.datetime.utcfromtimestamp(pe.FILE_HEADER.TimeDateStamp).isoformat()+'Z'
try:
    info['imphash'] = pe.get_imphash()
except Exception:
    info['imphash'] = None
info['sections'] = []
for s in pe.sections:
    name = s.Name.rstrip(b'\x00').decode(errors='replace')
    data = s.get_data()
    info['sections'].append({
        'name': name,
        'virtual_address': hex(s.VirtualAddress),
        'virtual_size': hex(s.Misc_VirtualSize),
        'raw_size': hex(s.SizeOfRawData),
        'entropy': round(entropy(data), 3),
        'characteristics': hex(s.Characteristics),
    })
with open(os.path.join(outdir, "13_pe_metadata.json"), "w") as f:
    json.dump(info, f, indent=2)
# also CSV for sections
with open(os.path.join(outdir, "14_section_entropy.csv"), "w") as f:
    f.write("name,virtual_address,virtual_size,raw_size,entropy,characteristics\n")
    for s in info['sections']:
        f.write("{name},{virtual_address},{virtual_size},{raw_size},{entropy},{characteristics}\n".format(**s))
PY

  # 04) Packer/format check
  msg "Packer heuristics..."
  (upx -l "$SAMPLE" || true)          > "$OUTDIR/15_upx_list.txt"
  if command -v diec >/dev/null 2>&1; then
    (diec -e "$SAMPLE" || true)       > "$OUTDIR/16_die_report.txt"
  fi

  # 05) Binwalk & ExifTool
  (binwalk "$SAMPLE" || true)         > "$OUTDIR/17_binwalk.txt"
  (exiftool "$SAMPLE" || true)        > "$OUTDIR/18_exiftool.txt"

  # 06) Radare2 quickscan (functions/sections/imports + entry disasm)
  msg "radare2 quick analysis..."
  r2 -q -e scr.color=false \
     -c "aaa; iS; ii; afl; s entry0; af; pdf; s 0x140000000; af" \
     -- "$SAMPLE" > "$OUTDIR/19_r2_quickscan.txt" || true

  # 07) capa (MITRE ATT&CK mapping)
  if command -v capa >/dev/null 2>&1; then
    msg "capa analysis (ATT&CK mapping)..."
    (capa -q "$SAMPLE" || true)       > "$OUTDIR/20_capa_report.txt"
    (capa -q -j "$SAMPLE" || true)    > "$OUTDIR/21_capa_report.json"
    # Summarize ATT&CK techniques via jq if available
    if command -v jq >/dev/null 2>&1; then
      python3 - "$OUTDIR/21_capa_report.json" "$OUTDIR/22_mitre_summary.txt" <<'PY'
import json,sys
j=json.load(open(sys.argv[1]))
# capa JSON structure varies by version; collect ATT&CK tags from rules & findings
seen=set()
lines=[]
def add(tag):
    tag=tag.strip()
    if tag and tag not in seen:
        seen.add(tag); lines.append(tag)
# Try rules.meta.att&ck
for r in j.get('rules',[]):
    meta=r.get('meta',{})
    for k in ('att&ck','attck','mitre','mitre_attack'):
        v=meta.get(k,[])
        if isinstance(v,str): v=[v]
        for t in v: add(t)
# Try top-level findings (if present)
for f in j.get('features',[]) + j.get('matches',[]):
    m=f.get('meta',{})
    for k in ('att&ck','attck','mitre','mitre_attack'):
        v=m.get(k,[])
        if isinstance(v,str): v=[v]
        for t in v: add(t)
open(sys.argv[2],"w").write("\n".join(sorted(lines)) or "No ATT&CK techniques found by capa.\n")
PY
    fi
  else
    warn "capa not installed – skipping MITRE mapping."
  fi

  # 08) Optional: YARA scan (if rules dir provided)
  if [[ -n "${YARA_RULES}" && -d "${YARA_RULES}" ]]; then
    msg "Running YARA rules from: $YARA_RULES"
    # compile rules for speed; ignore failures
    (yara -w -r "$YARA_RULES" "$SAMPLE" || true) > "$OUTDIR/23_yara_hits.txt"
  fi

  # 09) Optional: RetDec decompile (can be slow)
  if [[ "${RETDEC_SWITCH}" == "on" ]] && command -v retdec-decompiler.py >/dev/null 2>&1; then
    msg "RetDec decompiling (this can take a while)..."
    timeout 600 retdec-decompiler.py --cleanup --stop-after=decompile \
      -o "$OUTDIR/24_retdec.c" "$SAMPLE" || warn "RetDec timeout/failed (skipping)"
  fi

  # 10) Final summary
  {
    echo "== SUMMARY =="
    echo "Sample: $SAMPLE"
    echo -n "SHA256: "; cat "$OUTDIR/hash_sha256.txt" 2>/dev/null | awk '{print $1}'
    echo -n "File type: "; head -n1 "$OUTDIR/01_file.txt" 2>/dev/null | cut -d: -f2-
    echo "Sections:"
    awk 'NR>2{print $0}' "$OUTDIR/04_sections_rabin2.txt" 2>/dev/null | sed -n '1,8p'
    if [[ -s "$OUTDIR/22_mitre_summary.txt" ]]; then
      echo; echo "MITRE ATT&CK (from capa):"
      cat "$OUTDIR/22_mitre_summary.txt"
    fi
  } > "$OUTDIR/00_summary.txt"

  ok "Analysis complete. Artifacts saved in: $OUTDIR"
}

main() {
  local MODE="${1:-}"; shift || true
  case "$MODE" in
    install) install_tools ;;
    analyze) analyze_sample "$@" ;;
    *) usage ;;
  esac
}
main "$@"
